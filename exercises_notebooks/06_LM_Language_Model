{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06_LM_Language_Model","provenance":[{"file_id":"https://github.com/liadmagen/NLP-Course/blob/master/exercises_notebooks/06_LM_Language_Model.ipynb","timestamp":1643022525803}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hHpU4n2ZAd2p"},"source":["# Language Model Example\n","\n","In this notebook, you'll train a n-gram Language model yourself"]},{"cell_type":"markdown","metadata":{"id":"uYs_Dhab9syd"},"source":["This example is based on:\n","\n","https://nlpforhackers.io/language-models/\n","\n","For a (very!) detailed information about this topic, please refer to:\n","https://web.stanford.edu/~jurafsky/slp3/3.pdf "]},{"cell_type":"markdown","metadata":{"id":"Gxk8CHMfAr1H"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"piIx18HE_dlq","outputId":"bf8db56d-257d-4536-d380-e66723b875ce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643022757259,"user_tz":-60,"elapsed":243,"user":{"displayName":"liad magen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03421638585722407653"}}},"source":["import nltk\n","nltk.download('reuters')\n","nltk.download('punkt')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package reuters to /usr/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# NOTE: This step is only necessary due to limitation of Google Colab to unzip \n","# the reuters corpora. It is not needed when using nltk on your computer.\n","\n","from zipfile import ZipFile\n","\n","file_loc = '/root/nltk_data/corpora/reuters.zip'\n","\n","with ZipFile(file_loc, 'r') as z:\n","  z.extractall('/root/nltk_data/corpora/')"],"metadata":{"id":"lRJYAcADzmQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JjCnv0889m7r"},"source":["import random\n","from functools import reduce\n","\n","from operator import mul\n","from collections import Counter\n","\n","from nltk.corpus import reuters\n","from nltk import bigrams, trigrams\n","from collections import Counter, defaultdict\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uj4-vpdmAuLu"},"source":["# Bag-of-words & Frequency calculation\n","\n","We start by constructing a Bag-of-words.\n","\n","Remind yourself that a Language Model is a calculation of the frequencies and the probabilities of words, based on their observed occurrences.\n","\n","We calculate the word frequencies, by simply counting the word occurrences."]},{"cell_type":"code","source":["reuters.words()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjQ14BTLyfVt","executionInfo":{"status":"ok","timestamp":1643023311465,"user_tz":-60,"elapsed":553,"user":{"displayName":"liad magen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03421638585722407653"}},"outputId":"9410ba9d-78ef-47c3-e23b-557daa91a741"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', ...]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"sI732WCZ9wsv","outputId":"faa77e51-b9a4-49b0-98e1-892a8269e8d4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643023326850,"user_tz":-60,"elapsed":7745,"user":{"displayName":"liad magen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03421638585722407653"}}},"source":["counts = Counter(reuters.words())\n","total_count = len(reuters.words())\n","\n","print(counts.most_common(n=20))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('.', 94687), (',', 72360), ('the', 58251), ('of', 35979), ('to', 34035), ('in', 26478), ('said', 25224), ('and', 25043), ('a', 23492), ('mln', 18037), ('vs', 14120), ('-', 13705), ('for', 12785), ('dlrs', 11730), (\"'\", 11272), ('The', 10968), ('000', 10277), ('1', 9977), ('s', 9298), ('pct', 9093)]\n"]}]},{"cell_type":"code","metadata":{"id":"WnxBoLt6-Rsz","executionInfo":{"status":"ok","timestamp":1643023337150,"user_tz":-60,"elapsed":287,"user":{"displayName":"liad magen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03421638585722407653"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c7cc15e-74cb-494e-fc68-7e9f5cc9f33c"},"source":["# Compute the frequencies\n","for word in counts:\n","    counts[word] /= float(total_count)\n","\n","# The frequencies should add up to 1\n","print(sum(counts.values()))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.0000000000006808\n"]}]},{"cell_type":"markdown","metadata":{"id":"Pzx-cyghBJzA"},"source":["Let's create a random text passage, and calculate what is the probability that such a sentence is valid.\n","\n","Before continuing, and executing the next cells: \n","\n","**please pause and guess:**\n","* what do you expect that the probability of a random 5 words passage would be? \n","* How about a 100 random words?"]},{"cell_type":"code","metadata":{"id":"P4FefXrB9_YN"},"source":[" # Generate 100 words of language\n","text = []\n"," \n","for _ in range(100):\n","    r = random.random()\n","    accumulator = .0\n"," \n","    for word, freq in counts.items():\n","        accumulator += freq\n"," \n","        if accumulator >= r:\n","            text.append(word)\n","            break\n"," \n","print(' '.join(text))\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YzlH_2nW-gyQ"},"source":["# The probability of the text\n","\n","print(reduce(mul, [counts[w] for w in text], 1.0))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WDctxYLcBooF"},"source":["Compare the given probability above to the one you've previously guessed.\n","\n","Try changing the number of words and compare the results\n"]},{"cell_type":"markdown","metadata":{"id":"ftXjYNnKCMaT"},"source":["# n-gram Language Model"]},{"cell_type":"markdown","metadata":{"id":"_pIOV53YCPrb"},"source":["Now let's construct a n-grams language model from the text.\n","\n","nltk already has functions for n-grams such as: `bigrams` & `trigrams`.\n","\n","Let's use them:"]},{"cell_type":"code","metadata":{"id":"nZZzik2A_SZR","executionInfo":{"status":"ok","timestamp":1643023572698,"user_tz":-60,"elapsed":681,"user":{"displayName":"liad magen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03421638585722407653"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9eafc875-6f23-4936-9357-e2bfa75f40d2"},"source":["first_sentence = reuters.sents()[0]\n","print(first_sentence)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.']\n"]}]},{"cell_type":"code","metadata":{"id":"ifXUjkxJ_518","executionInfo":{"status":"ok","timestamp":1643023572701,"user_tz":-60,"elapsed":19,"user":{"displayName":"liad magen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03421638585722407653"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cf88a588-487f-44b7-9596-af5bcbfe7972"},"source":["# Get the bigrams\n","print(list(bigrams(first_sentence)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('ASIAN', 'EXPORTERS'), ('EXPORTERS', 'FEAR'), ('FEAR', 'DAMAGE'), ('DAMAGE', 'FROM'), ('FROM', 'U'), ('U', '.'), ('.', 'S'), ('S', '.-'), ('.-', 'JAPAN'), ('JAPAN', 'RIFT'), ('RIFT', 'Mounting'), ('Mounting', 'trade'), ('trade', 'friction'), ('friction', 'between'), ('between', 'the'), ('the', 'U'), ('U', '.'), ('.', 'S'), ('S', '.'), ('.', 'And'), ('And', 'Japan'), ('Japan', 'has'), ('has', 'raised'), ('raised', 'fears'), ('fears', 'among'), ('among', 'many'), ('many', 'of'), ('of', 'Asia'), ('Asia', \"'\"), (\"'\", 's'), ('s', 'exporting'), ('exporting', 'nations'), ('nations', 'that'), ('that', 'the'), ('the', 'row'), ('row', 'could'), ('could', 'inflict'), ('inflict', 'far'), ('far', '-'), ('-', 'reaching'), ('reaching', 'economic'), ('economic', 'damage'), ('damage', ','), (',', 'businessmen'), ('businessmen', 'and'), ('and', 'officials'), ('officials', 'said'), ('said', '.')]\n"]}]},{"cell_type":"code","metadata":{"id":"xWRQ3iJwASBT","executionInfo":{"status":"ok","timestamp":1643023598736,"user_tz":-60,"elapsed":251,"user":{"displayName":"liad magen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03421638585722407653"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1c577947-fc07-43c8-d84d-9a3ec4530980"},"source":["# Get the padded bigrams\n","print(list(bigrams(first_sentence, pad_left=True, pad_right=True)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[(None, 'ASIAN'), ('ASIAN', 'EXPORTERS'), ('EXPORTERS', 'FEAR'), ('FEAR', 'DAMAGE'), ('DAMAGE', 'FROM'), ('FROM', 'U'), ('U', '.'), ('.', 'S'), ('S', '.-'), ('.-', 'JAPAN'), ('JAPAN', 'RIFT'), ('RIFT', 'Mounting'), ('Mounting', 'trade'), ('trade', 'friction'), ('friction', 'between'), ('between', 'the'), ('the', 'U'), ('U', '.'), ('.', 'S'), ('S', '.'), ('.', 'And'), ('And', 'Japan'), ('Japan', 'has'), ('has', 'raised'), ('raised', 'fears'), ('fears', 'among'), ('among', 'many'), ('many', 'of'), ('of', 'Asia'), ('Asia', \"'\"), (\"'\", 's'), ('s', 'exporting'), ('exporting', 'nations'), ('nations', 'that'), ('that', 'the'), ('the', 'row'), ('row', 'could'), ('could', 'inflict'), ('inflict', 'far'), ('far', '-'), ('-', 'reaching'), ('reaching', 'economic'), ('economic', 'damage'), ('damage', ','), (',', 'businessmen'), ('businessmen', 'and'), ('and', 'officials'), ('officials', 'said'), ('said', '.'), ('.', None)]\n"]}]},{"cell_type":"code","metadata":{"id":"Ow0OeOo3AS7R","executionInfo":{"status":"ok","timestamp":1643023611386,"user_tz":-60,"elapsed":312,"user":{"displayName":"liad magen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03421638585722407653"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"081ff07b-2a67-4456-abe9-da1e6361c6a4"},"source":["# Get the trigrams\n","print(list(trigrams(first_sentence)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('ASIAN', 'EXPORTERS', 'FEAR'), ('EXPORTERS', 'FEAR', 'DAMAGE'), ('FEAR', 'DAMAGE', 'FROM'), ('DAMAGE', 'FROM', 'U'), ('FROM', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.-'), ('S', '.-', 'JAPAN'), ('.-', 'JAPAN', 'RIFT'), ('JAPAN', 'RIFT', 'Mounting'), ('RIFT', 'Mounting', 'trade'), ('Mounting', 'trade', 'friction'), ('trade', 'friction', 'between'), ('friction', 'between', 'the'), ('between', 'the', 'U'), ('the', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.'), ('S', '.', 'And'), ('.', 'And', 'Japan'), ('And', 'Japan', 'has'), ('Japan', 'has', 'raised'), ('has', 'raised', 'fears'), ('raised', 'fears', 'among'), ('fears', 'among', 'many'), ('among', 'many', 'of'), ('many', 'of', 'Asia'), ('of', 'Asia', \"'\"), ('Asia', \"'\", 's'), (\"'\", 's', 'exporting'), ('s', 'exporting', 'nations'), ('exporting', 'nations', 'that'), ('nations', 'that', 'the'), ('that', 'the', 'row'), ('the', 'row', 'could'), ('row', 'could', 'inflict'), ('could', 'inflict', 'far'), ('inflict', 'far', '-'), ('far', '-', 'reaching'), ('-', 'reaching', 'economic'), ('reaching', 'economic', 'damage'), ('economic', 'damage', ','), ('damage', ',', 'businessmen'), (',', 'businessmen', 'and'), ('businessmen', 'and', 'officials'), ('and', 'officials', 'said'), ('officials', 'said', '.')]\n"]}]},{"cell_type":"code","metadata":{"id":"BxnGokXfAT5N","executionInfo":{"status":"ok","timestamp":1643023613875,"user_tz":-60,"elapsed":254,"user":{"displayName":"liad magen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03421638585722407653"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f0bb39b-ff10-4416-89e8-c875ba1cd591"},"source":["# Get the padded trigrams\n","print(list(trigrams(first_sentence, pad_left=True, pad_right=True)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[(None, None, 'ASIAN'), (None, 'ASIAN', 'EXPORTERS'), ('ASIAN', 'EXPORTERS', 'FEAR'), ('EXPORTERS', 'FEAR', 'DAMAGE'), ('FEAR', 'DAMAGE', 'FROM'), ('DAMAGE', 'FROM', 'U'), ('FROM', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.-'), ('S', '.-', 'JAPAN'), ('.-', 'JAPAN', 'RIFT'), ('JAPAN', 'RIFT', 'Mounting'), ('RIFT', 'Mounting', 'trade'), ('Mounting', 'trade', 'friction'), ('trade', 'friction', 'between'), ('friction', 'between', 'the'), ('between', 'the', 'U'), ('the', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.'), ('S', '.', 'And'), ('.', 'And', 'Japan'), ('And', 'Japan', 'has'), ('Japan', 'has', 'raised'), ('has', 'raised', 'fears'), ('raised', 'fears', 'among'), ('fears', 'among', 'many'), ('among', 'many', 'of'), ('many', 'of', 'Asia'), ('of', 'Asia', \"'\"), ('Asia', \"'\", 's'), (\"'\", 's', 'exporting'), ('s', 'exporting', 'nations'), ('exporting', 'nations', 'that'), ('nations', 'that', 'the'), ('that', 'the', 'row'), ('the', 'row', 'could'), ('row', 'could', 'inflict'), ('could', 'inflict', 'far'), ('inflict', 'far', '-'), ('far', '-', 'reaching'), ('-', 'reaching', 'economic'), ('reaching', 'economic', 'damage'), ('economic', 'damage', ','), ('damage', ',', 'businessmen'), (',', 'businessmen', 'and'), ('businessmen', 'and', 'officials'), ('and', 'officials', 'said'), ('officials', 'said', '.'), ('said', '.', None), ('.', None, None)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"zmTKkqbJCjAQ"},"source":["Let's use the trigrams on the Reuters corpus.\n","\n","We start by counting the occurences:"]},{"cell_type":"code","metadata":{"id":"1CGdcS-wAVX0","executionInfo":{"status":"ok","timestamp":1643023632708,"user_tz":-60,"elapsed":11498,"user":{"displayName":"liad magen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03421638585722407653"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"26b7daf5-c236-4d8b-8b27-f1428b88cef4"},"source":["model = defaultdict(lambda: defaultdict(lambda: 0))\n"," \n","for sentence in reuters.sents():\n","    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n","        model[(w1, w2)][w3] += 1\n"," \n"," \n","print(model[\"what\", \"the\"][\"economists\"])\n","print(model[\"what\", \"the\"][\"nonexistingword\"])\n","print(model[None, None][\"The\"])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","0\n","8839\n"]}]},{"cell_type":"markdown","metadata":{"id":"x_L2wmE4DLLd"},"source":["And then converting it into frequencies or probabilities, by deviding these occurences by the total number of occurences of the first 2 words of our trigrams:"]},{"cell_type":"code","metadata":{"id":"YFVttrieC8RF"},"source":["# Let's transform the counts to probabilities\n","for w1_w2 in model:\n","    total_count = float(sum(model[w1_w2].values()))\n","    for w3 in model[w1_w2]:\n","        model[w1_w2][w3] /= total_count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P5AlcTmgJs0T","executionInfo":{"status":"ok","timestamp":1643023642063,"user_tz":-60,"elapsed":267,"user":{"displayName":"liad magen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03421638585722407653"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8822bf56-a61c-4637-a2b0-f61eeaeb8b84"},"source":["print(model[\"what\", \"the\"][\"economists\"])\n","print(model[\"what\", \"the\"][\"nonexistingword\"])\n","print(model[None, None][\"The\"])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.043478260869565216\n","0.0\n","0.16154324146501936\n"]}]},{"cell_type":"markdown","metadata":{"id":"U8F8Y2lVDqLV"},"source":["---\n","\n","Now we're ready to try it out.\n","\n","Let's generate a random sentence again, but this time, we'll use our trigram model:"]},{"cell_type":"code","metadata":{"id":"FhkojQA3Di_p","executionInfo":{"status":"ok","timestamp":1643023689764,"user_tz":-60,"elapsed":256,"user":{"displayName":"liad magen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03421638585722407653"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d0f8d24-5bb7-4d61-eebe-8866dc1106fe"},"source":["text = [None, None]\n","prob = 1.0 \n"," \n","sentence_finished = False\n"," \n","while not sentence_finished:\n","    r = random.random()\n","    accumulator = .0\n"," \n","    for word in model[tuple(text[-2:])].keys():\n","        accumulator += model[tuple(text[-2:])][word]\n"," \n","        if accumulator >= r:\n","            prob *= model[tuple(text[-2:])][word] \n","            text.append(word)\n","            break\n"," \n","    if text[-2:] == [None, None]:\n","        sentence_finished = True\n"," \n","print(f'Probability of text={prob}')\n","print(' '.join([t for t in text if t]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Probability of text=1.7853035120476352e-38\n","AMERICAN BUILDING MAINTENANCE & lt ; TGT > TO ACQUIRE LICENSEE Blockbuster Entertainment Corp said it terminated plans to seek control of the risk of building a stake in First of America locals on strike for an undisclosed amount of pressure on the USAir board .\n"]}]},{"cell_type":"markdown","metadata":{"id":"FMQG202UD0aD"},"source":["Try running the previous cell several times, and compare the output sentences to the previous random ones.\n","\n","> Which one looks better to you?\n"," \n","> Can you explain why?\n","\n","\n","Note that we have not used here complicated RNN or LSTM, and still managed to generate reasonable sentences, using only simple probability, and counting words."]},{"cell_type":"markdown","metadata":{"id":"o2CyR3qoFt1G"},"source":["---\n","\n","## Exercise\n","\n","Your Turn:\n","\n","### Task 1\n","- Optional: use your own corpus\n","- Create a function that parse the text into 4-grams\n","- Train a language model using the 4-grmams and\n","- Generate few sentences."]},{"cell_type":"markdown","metadata":{"id":"31Ht7Wu44mY4"},"source":["Q: How can you use your language model as a spelling or grammar checker?\n","\n","Q2: What steps are needed to create a spelling or grammar correction suggestion using your language model? "]},{"cell_type":"markdown","metadata":{"id":"JKlyMas_4kBh"},"source":["\n","### Task 2:\n","- Can you improve the words generation even further? \n","\n","  Hint: Check the usage of the `random.random()` - what is it for? Can you come up with a better alternative? \n","\n","- Do the new sentences look better? Do they make more sense?"]},{"cell_type":"code","metadata":{"id":"ZySTIWy3Dn14"},"source":[""],"execution_count":null,"outputs":[]}]}