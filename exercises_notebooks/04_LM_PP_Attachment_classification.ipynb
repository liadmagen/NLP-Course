{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_LM_PP_Attachment_classification",
      "provenance": [],
      "collapsed_sections": [
        "ZEHsHqnBEnM0",
        "MRYNWqK-Gu3F",
        "vyls_Vs7MxYj"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd8ae80cc4704eaeb53dd420c860780c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afbe8e962e7f491e810421b31fa6f4dc",
              "IPY_MODEL_a4ddc41ed6d348fea0dd24101a05b61f",
              "IPY_MODEL_e905c46a3e8c45939802e8f391eac7c4"
            ],
            "layout": "IPY_MODEL_7434a567e30e4d27a92f9e6b7da7451f"
          }
        },
        "afbe8e962e7f491e810421b31fa6f4dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb78fd2ff49a47168aeb150ea62587b0",
            "placeholder": "​",
            "style": "IPY_MODEL_6cdbfdf25ae7480990f6bec3be5af042",
            "value": ""
          }
        },
        "a4ddc41ed6d348fea0dd24101a05b61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21e7997920304d9fa40ac980ccaa23a8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c459ae9bc0914cceb22f5c0f636293ce",
            "value": 1
          }
        },
        "e905c46a3e8c45939802e8f391eac7c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a736964320a40e58619af6f1a457f76",
            "placeholder": "​",
            "style": "IPY_MODEL_68b10d056a4442cd9db79ddea92717e7",
            "value": " 25858/? [00:00&lt;00:00, 152386.89it/s]"
          }
        },
        "7434a567e30e4d27a92f9e6b7da7451f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb78fd2ff49a47168aeb150ea62587b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cdbfdf25ae7480990f6bec3be5af042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21e7997920304d9fa40ac980ccaa23a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c459ae9bc0914cceb22f5c0f636293ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a736964320a40e58619af6f1a457f76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68b10d056a4442cd9db79ddea92717e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liadmagen/NLP-Course/blob/master/exercises_notebooks/04_LM_PP_Attachment_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-EolZK1El9L"
      },
      "source": [
        "# PP Attachment "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Preposition Phrase attachment problem is the difficulty to decide if a preposition in a sentence is attached to a verb or a noun.\n",
        "\n",
        "In some cases it may even confuse the reader. For example, the sentence:\n",
        "\n",
        "> San Jose cops kill man with a knife\n",
        "\n",
        "can be interpreted as either the man or the cops had a knife. The difference in the syntax parsing would be attaching the preposition phrase either to the Verb Phrase (\"kill with knife\")\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "or to the Noun Phrase (\"man with knife\").\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "ndm17vHr9oR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's try out the Preposition Phrase attachment classification!\n",
        "\n",
        "Through this exercise, you'll practice classification of linguistic aspects of text."
      ],
      "metadata": {
        "id": "gddvmPua9ncH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEHsHqnBEnM0"
      },
      "source": [
        "# Setup\n",
        "Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQeJMBC9EjQj"
      },
      "source": [
        "import csv\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "from random import choice\n",
        "from urllib.request import urlopen\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5y8hLSTDcmT"
      },
      "source": [
        "def read_pp_examples(file_url: str) -> List[Dict]:\n",
        "  \"\"\"Reads the pp samples from a remtoe url and loads them into a dictionary\n",
        "\n",
        "  Args:\n",
        "      file_url (str): a url to load the dataset from\n",
        "\n",
        "  Returns:\n",
        "      Dict: a dictionary with two keys: answer and pp\n",
        "  \"\"\"\n",
        "  pp_examples = []\n",
        "  \n",
        "  for line in tqdm(urlopen(file_url)):\n",
        "    line = line.decode(\"utf-8\").strip().split()\n",
        "    assert(len(line) == 5)\n",
        "    v,n1,p,n2,answer = line\n",
        "    pp_examples.append( {'answer':answer,'keywords':(v,n1,p,n2)} )\n",
        "  return pp_examples"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kc6IkpCDphJ"
      },
      "source": [
        "pp_samples_url = 'https://raw.githubusercontent.com/liadmagen/NLP-Course/master/dataset/pp_examples.txt'"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i0rtj1RFkug",
        "outputId": "5f423450-f265-4783-c1bc-b677275944f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "cd8ae80cc4704eaeb53dd420c860780c",
            "afbe8e962e7f491e810421b31fa6f4dc",
            "a4ddc41ed6d348fea0dd24101a05b61f",
            "e905c46a3e8c45939802e8f391eac7c4",
            "7434a567e30e4d27a92f9e6b7da7451f",
            "fb78fd2ff49a47168aeb150ea62587b0",
            "6cdbfdf25ae7480990f6bec3be5af042",
            "21e7997920304d9fa40ac980ccaa23a8",
            "c459ae9bc0914cceb22f5c0f636293ce",
            "8a736964320a40e58619af6f1a457f76",
            "68b10d056a4442cd9db79ddea92717e7"
          ],
          "height": 0
        }
      },
      "source": [
        "pp_examples = read_pp_examples(pp_samples_url)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd8ae80cc4704eaeb53dd420c860780c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRYNWqK-Gu3F"
      },
      "source": [
        "# Step #1 - Look at the data\n",
        "\n",
        "Step 1 is (always) to examine the data!\n",
        "\n",
        "That means to check the data statistics, load some sample at random and ensure it is correctly labeled, and if possible, plot and visualize the data (histograms, distribution, etc.). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a59ypmWhGlIZ",
        "outputId": "4a0c0919-b5b2-45bf-978d-d6ca62e5c223",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"There are {len(pp_examples)} samples in the dataset\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 25858 samples in the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W9FOJmkG1HF",
        "outputId": "700edb2d-8d9a-44b1-ba43-a593b18e699e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(choice(pp_examples))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer': 'N', 'keywords': ('take', 'responsibility', 'for', 'effort')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, we can reach the dictionary's parts by specifying the key in a squared brackets. "
      ],
      "metadata": {
        "id": "avutga3uvG29"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLCTVAyAG4Cm",
        "outputId": "f978b1ba-91e2-4546-a5cb-1749d807f5b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "random_example = choice(pp_examples)\n",
        "random_example['keywords']"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('be', 'need', 'for', 'copper')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4tkr91VHHC0",
        "outputId": "4b907aa7-89cf-4f80-e64e-53aae6082d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "random_example['answer']"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'N'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyls_Vs7MxYj"
      },
      "source": [
        "# Step 2: Deciding on the measurement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1Av7fCNHN2K",
        "outputId": "68d16e61-b3f6-4dea-d899-c40d14f9f51a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# we can split the dataset simply through dividing the list \n",
        "\n",
        "amt = int(0.75 * len(pp_examples))\n",
        "train_examples, test_examples = pp_examples[:amt], pp_examples[amt:]\n",
        "\n",
        "print(len(train_examples), len(test_examples))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19393 6465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds9ZfBzmNXjN"
      },
      "source": [
        "We'll define a classifier evaluator.\n",
        "\n",
        "Given a set of examples and an evaluator, it returns the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-uR21gwNGo1"
      },
      "source": [
        "def evaluate_classifier(examples, pp_resolver):\n",
        "  \"\"\"evaluate the classifier and returns the accuracy score.\n",
        "\n",
        "  Args:\n",
        "      examples (List): a list of {'keywords':(v,n1,p,n2), 'answer':answer }\n",
        "      pp_resolver (_type_): a model with a classify() function that maps from \n",
        "        (v,n1,p,n2) to 'N' / 'V'\n",
        "\n",
        "  Returns:\n",
        "      float: The accurcy score of the classifier\n",
        "  \"\"\"\n",
        "  correct = 0.0\n",
        "  incorrect = 0.0\n",
        "  for example in examples:\n",
        "      answer = pp_resolver.classify(example['keywords'])\n",
        "      if answer == example['answer']:\n",
        "          correct += 1\n",
        "      else:\n",
        "          incorrect += 1\n",
        "  return correct / (correct + incorrect)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8v47ip3OkRi"
      },
      "source": [
        "# Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUdapHv7NzVD"
      },
      "source": [
        "Let's test it on an extremely naive classifiers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9gXjgytNJLN"
      },
      "source": [
        "class AlwaysSayN:\n",
        "    \"\"\"\n",
        "    This naive clasifier answers always with 'Noun'\n",
        "    \"\"\"\n",
        "    def __init__(self): pass\n",
        "    def classify(self, pp):\n",
        "        return 'N'\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7DkSKB1NScS"
      },
      "source": [
        "class AlwaysSayV:\n",
        "    \"\"\"\n",
        "    This naive clasifier answers always with 'Verb'\n",
        "    \"\"\"\n",
        "    def __init__(self): pass\n",
        "    def classify(self, pp):\n",
        "        return 'V'\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_classifier(test_examples, AlwaysSayV())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk8WtRXdtr1D",
        "outputId": "33b3c7ee-1fa8-425b-bbc7-0978c24f03a8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4634184068058778"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y61B9XkjNT2u",
        "outputId": "80ae126e-3c14-4ea4-b956-e23ad122277f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate_classifier(test_examples, AlwaysSayN())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5365815931941222"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xHV9Q9WOOFC"
      },
      "source": [
        "We can see that saying always 'Noun', leads to an accuracy result of 53%.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "It also means that our dataset is quite balaneced ;)\n",
        "\n",
        "We could, instead, have tested which class has the majority and simply select it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eozkgMzfOCWD"
      },
      "source": [
        "class MajorityClassResolver:\n",
        "  def __init__(self, training_examples: List):\n",
        "    \"\"\"Initializes the class, testing which class is the majority and saves it as a property.\n",
        "\n",
        "    Args:\n",
        "        training_examples (List): A list of dictionary training examples.\n",
        "    \"\"\"\n",
        "    answers = [item['answer'] for item in training_examples]\n",
        "    num_n = len([a for a in answers if a == 'N'])\n",
        "    num_v = len([a for a in answers if a == 'V'])\n",
        "    if num_v > num_n:\n",
        "        self.answer = 'V'\n",
        "    else:\n",
        "        self.answer = 'N'\n",
        "\n",
        "  def classify(self, pp: Tuple) -> str:\n",
        "    \"\"\"classify a 4 keywords tuple as N or V attachment, based on the previously calculated majority class\n",
        "\n",
        "    Args:\n",
        "        pp (Tuple): a tuple of V, N1, PP, N2 to be classified\n",
        "\n",
        "    Returns:\n",
        "        str: the prediction - N or V\n",
        "    \"\"\"\n",
        "    return self.answer\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGM5CODLODIv",
        "outputId": "61a46b50-e4b5-4dbc-b4e3-8377b3d83204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate_classifier(test_examples, MajorityClassResolver(train_examples))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5365815931941222"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or make it a bit more sophisticated by peeking at the training examples:"
      ],
      "metadata": {
        "id": "1fQDTH8YuX9t"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVTth8ybNUkQ"
      },
      "source": [
        "class LookupResolver:\n",
        "  def __init__(self, training_examples: List):\n",
        "    \"\"\"Initializes the class, load all the training dataset into the memory and during prediction, return the answer if the keywords match a previously saved one. \n",
        "\n",
        "    Args:\n",
        "        training_examples (List): _description_\n",
        "    \"\"\"\n",
        "    self.answers = {}\n",
        "    for item in training_examples:\n",
        "        self.answers[item['keywords']] = item['answer']\n",
        "    self.backoff = MajorityClassResolver(training_examples)\n",
        "      \n",
        "  def classify(self, pp: Tuple) -> str:\n",
        "    \"\"\"Classify a 4 keywords tuple as N or V attachment.\n",
        "     If the tuple was found in the previously stored answers, return it.\n",
        "     Otherwise, return the majority class.\n",
        "\n",
        "    Args:\n",
        "        pp (Tuple): a tuple of V, N1, PP, N2 to be classified\n",
        "\n",
        "    Returns:\n",
        "        str: the prediction - N or V\n",
        "    \"\"\"\n",
        "    if pp in self.answers:\n",
        "        return self.answers[pp]\n",
        "    else:\n",
        "        return self.backoff.classify(pp)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to understand what is stored in the `answers` property, uncomment and run the following line:\n",
        "# LookupResolver(train_examples).answers"
      ],
      "metadata": {
        "id": "N_BBE-dM2-k4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqi-FzCAN71L",
        "outputId": "192e6413-4cd9-4b1d-b804-2f76af0fecbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate_classifier(test_examples, LookupResolver(train_examples))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6009280742459396"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm2DFH7YPN_Z"
      },
      "source": [
        "# Exercise - Your Turn:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFRReTKOHTN8"
      },
      "source": [
        "Implement a discriminative PP-attachment model, using a classifier of your choice (i.e. - Naive Bayes Classifier https://web.stanford.edu/~jurafsky/slp3/4.pdf, [Support Vector Machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC), etc.) from a toolkit such as [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB).\n",
        "\n",
        "Please take a good look at the data beforehand. Try to answer questions such as:\n",
        "- What is the frequency of the propesitions? \n",
        "- Which prepositions are a clear indicator to be almost only V or N? Or in other words, which pair frequency of preposition and the answer is above 90?\n",
        "- Which prepositionas are relatively \"confusing\"? e.g., their frequency is almost equal for V and N.\n",
        "- Which words are frequent as verbs? as first noun? as second noun?\n",
        "\n",
        "Regarding the model itself, try to think which features may be helpful.\n",
        "\n",
        "Possible features for back-off algorithm or ML one:\n",
        "\n",
        "Single items ​\n",
        "* Identity of v ​\n",
        "* Identity of p ​\n",
        "* Identity of n1 ​\n",
        "* Identity of n2 ​\n",
        "\n",
        "Pairs:​\n",
        "* dentity of (v, p) ​\n",
        "* Identity of (n1, p) ​\n",
        "* Identity of (p, n1)​\n",
        "\n",
        "Triplets:​\n",
        "* Identity of (v, n1, p)​\n",
        "* Identity of (v, p, n2) ​\n",
        "* Identity of (n1, p, n2) ​\n",
        "\n",
        "Quadruple:​\n",
        "* Identity of (v, n1, p, n2)​\n",
        "\n",
        "\n",
        "Corpus Level:​\n",
        "\n",
        "* Have we seen the (v, p) pair in a 5-word window in a big corpus?​\n",
        "* Have we seen the (n1, p) pair in a 5-word window in a big corpus? ​\n",
        "* Have we seen the (n1, p, n2) triplet in a 5-word window in a big corpus?​\n",
        "*  Also: we can use counts, or binned counts.​\n",
        "* You can use a bigger corpus for additional training purposes as well.\n",
        "\n",
        "If we had the original sentnces, we could have used a distance feature, such as:​\n",
        "* Distance (in words) between v and p ​\n",
        "* Distance (in words) between n1 and p​\n",
        "\n",
        "However, you can try implementing the average distance (in words) from a larger corpus.\n",
        "\n",
        "Additionally, think which other methods we learned that could help. Looking at the data might give you some ideas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the corpus level features, you can simply load one of the english corpuses in NLTK (such as [brown - but don't forget to download it first](https://www.nltk.org/book/ch02.html)). If you use a tagged corpus - such that the words are tagged by their parts of speech, you can create more interesting linguistic-related features.\n",
        "\n",
        "You can also consider using [WordNet](https://wordnet.princeton.edu/), a large *lexical* database of English words, which is also [implemented in NLTK](https://www.nltk.org/howto/wordnet.html). \n",
        "\n",
        "Finally, if you need inspiration and ideas, here are some selected papers:\n",
        "- [An Analysis of Prepositional-Phrase Attachment Disambiguation](http://ejournals.asia/stj1/ijclr2.pdf) - an overview of different papers dealing with this problem using different methods (kNN, SVN, etc.).\n",
        "- [The spy saw a cop with a telescope: Who has the telescope?](https://www.semanticscholar.org/paper/The-spy-saw-a-cop-with-a-telescope%3A-Who-has-the-Yan-Nguyen/3220ad0619b72404cb9b1acb9e093a8a564f0f4e) - An linguistic analysis of the potentials reasons (and features) to disambiguify pp attachment. \n",
        "- [PREPOSITIONAL PHRASE ATTACHMENT AMBIGUITY RESOLUTION USING SEMANTIC HIERARCHIES](https://eprints.mdx.ac.uk/2471/1/ppattachhier.pdf)\n",
        "- [Corpus Based PP Attachment Ambiguity Resolution with a Semantic Dictionary](https://aclanthology.org/W97-0109.pdf)"
      ],
      "metadata": {
        "id": "4mZAGEBA7K1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## On Generating N-Grams"
      ],
      "metadata": {
        "id": "Fe0J8DNxo7jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "hlZdaoi-TEXh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input of *any* machine learning model must be numerical. Since words (nor characters) aren’t numbers, we have to work a bit to convert them into a numerical representation.\n",
        "\n",
        "Such a numerical representation is also called a vector (a fancy name for a list of numbers…). A common way to achieve such vector is to perform measurements on the text (as we discussed in the first sessions – performing measurement on an apple). \n",
        "\n",
        "Such features could be the identity of a single word, given as an index number, or its frequency in a corpus or in the sentence, or TF-IDF on a corpus. Features can also be a composition of multiple words together (e.g., only the verb and the preposition), with the same or other techniques. This is also called an **n-gram**. \n",
        "\n",
        "One way to vectorize text is using that count transformer ([CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)) from scikit-learn. These vectorizers work in two part: \n",
        "*\tFirst they learn ([fit](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit)) from some input data. In the case of CountVectorizer, it expects a list of sentences (a corpus) to learn from. It will then learn how many different words (types) the corpus contains, and will build a vocabulary for those words: each word will get an index number. It also cleans up the text from stop words and punctuation, and you could even ask it to learn representations of n-grams, instead of single words (a parameter of the CountVectorizer itself).\n",
        "*\tAfter learning the size of the vocabulary, it can transform any list of text into a vectorized representation. Given a list of new text inputs, sentences in different lengths (also the list itself can be any length – for example, it can be made of a single sentence, but it has to be a list), the [transform](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.transform) method will return a vector representation in the size of the learned vocabulary, where every position represent a specific word (a type) from the learned corpus. The value on that position is the number of occurrences of that word in that given sentence. Piling up these three vectors, one on top of the other, would yield a matrix (a table / excel sheet of numbers), where every column represent a specific word in our vocabulary.\n",
        "*\t`X_transformed = vectorizer.fit_transform(X)` ▶ [fit_transform](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform) is a method that does both parts (fitting – counting the vocabulary types, and then converting that input text into the vector or even a matrix if there are more than one string) in one go.\n",
        "*\tThe result of the CountVectorizer is indeed a (sparse) matrix in a form of scipy’s scr_matrix. To convert it into an array, you can call its method “toarray()”:\n"
      ],
      "metadata": {
        "id": "GoJDQ5BjRD1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to use the CountVectorizer, we must convert the tuples into \"full\" sentences;\n",
        "joined_sentences = [' '.join(example['keywords']) for example in train_examples[:10]]\n",
        "joined_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5b1E6xMTGQM",
        "outputId": "e74d72ad-6934-4518-d3d3-8da13748e9d8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['creating obstacle to sale',\n",
              " 'restrict RTC to borrowings',\n",
              " 'maintain assets of thrifts',\n",
              " 'leaving spending for bailout',\n",
              " 'leaving spending at $',\n",
              " 'including interest over years',\n",
              " 'subtracting value of assets',\n",
              " 'say opponents of plan',\n",
              " 'pay price of consultation',\n",
              " 'want kind of flexibility']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer would, by default, tokenize the sentence by separating by \n",
        "# spaces and collect a vocabulary from all the different words it finds:\n",
        "vect = CountVectorizer()\n",
        "vect.fit(joined_sentences)\n",
        "print(f\"vocabulary size: {len(vect.vocabulary_)}\")\n",
        "vect.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDZ6jlsOUKli",
        "outputId": "7cb37e4c-c094-442b-fcee-696e155b28d7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary size: 31\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['assets', 'at', 'bailout', 'borrowings', 'consultation',\n",
              "       'creating', 'flexibility', 'for', 'including', 'interest', 'kind',\n",
              "       'leaving', 'maintain', 'obstacle', 'of', 'opponents', 'over',\n",
              "       'pay', 'plan', 'price', 'restrict', 'rtc', 'sale', 'say',\n",
              "       'spending', 'subtracting', 'thrifts', 'to', 'value', 'want',\n",
              "       'years'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use it to generate n-grams sized 1 (unigram) to 4:\n",
        "vect = CountVectorizer(ngram_range=(1, 4))\n",
        "vect.fit(joined_sentences)\n",
        "print(f\"vocabulary size: {len(vect.vocabulary_)}\")\n",
        "vect.get_feature_names_out()"
      ],
      "metadata": {
        "id": "SCDYy4wTFiK6",
        "outputId": "fcf925f7-ffc4-452e-ffa2-ce622f326541",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary size: 87\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['assets', 'assets of', 'assets of thrifts', 'at', 'bailout',\n",
              "       'borrowings', 'consultation', 'creating', 'creating obstacle',\n",
              "       'creating obstacle to', 'creating obstacle to sale', 'flexibility',\n",
              "       'for', 'for bailout', 'including', 'including interest',\n",
              "       'including interest over', 'including interest over years',\n",
              "       'interest', 'interest over', 'interest over years', 'kind',\n",
              "       'kind of', 'kind of flexibility', 'leaving', 'leaving spending',\n",
              "       'leaving spending at', 'leaving spending for',\n",
              "       'leaving spending for bailout', 'maintain', 'maintain assets',\n",
              "       'maintain assets of', 'maintain assets of thrifts', 'obstacle',\n",
              "       'obstacle to', 'obstacle to sale', 'of', 'of assets',\n",
              "       'of consultation', 'of flexibility', 'of plan', 'of thrifts',\n",
              "       'opponents', 'opponents of', 'opponents of plan', 'over',\n",
              "       'over years', 'pay', 'pay price', 'pay price of',\n",
              "       'pay price of consultation', 'plan', 'price', 'price of',\n",
              "       'price of consultation', 'restrict', 'restrict rtc',\n",
              "       'restrict rtc to', 'restrict rtc to borrowings', 'rtc', 'rtc to',\n",
              "       'rtc to borrowings', 'sale', 'say', 'say opponents',\n",
              "       'say opponents of', 'say opponents of plan', 'spending',\n",
              "       'spending at', 'spending for', 'spending for bailout',\n",
              "       'subtracting', 'subtracting value', 'subtracting value of',\n",
              "       'subtracting value of assets', 'thrifts', 'to', 'to borrowings',\n",
              "       'to sale', 'value', 'value of', 'value of assets', 'want',\n",
              "       'want kind', 'want kind of', 'want kind of flexibility', 'years'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifier Example\n",
        "\n",
        "Here is a simple example using Naive Bayes. It also illustrates the usage of object-oriented. Notice the `self.` - without it, any variable that you define will be \"killed\" by the end of the function execution. "
      ],
      "metadata": {
        "id": "ZuQ0zTI8F1_O"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfxK2XclN-PR",
        "outputId": "332a1db9-2b4d-4cb5-f4e2-aaee510f4bda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "  \"\"\"\n",
        "  This naive bayes clasifier is trained using a Multinomial Naive Bayes\n",
        "  \"\"\"\n",
        "  def __init__(self, training_examples: List):\n",
        "\n",
        "    # convert the data into lists (of sentences / of V/N chars)\n",
        "    X = [' '.join(example['keywords']) for example in training_examples]\n",
        "    y = [example['answer'] for example in training_examples]\n",
        "\n",
        "    # convert the text into numerical values. Here we're using CountVectorizer\n",
        "    self.vectorizer = CountVectorizer()\n",
        "\n",
        "    # fit_transforms fits the vectorizer on the test and converts it to vector\n",
        "    X_transformed = self.vectorizer.fit_transform(X)\n",
        "\n",
        "    # create a classifier and train it on the data\n",
        "    self.classifier = MultinomialNB()\n",
        "    self.classifier.fit(X_transformed, y)\n",
        "\n",
        "  def classify(self, pp: Tuple):\n",
        "    # converting the 4-words tuple into a sentnce, separated with spaces: \n",
        "    joined_sentence = \" \".join(pp)\n",
        "\n",
        "    # Vectorizing the sentence.\n",
        "    # The vectorizer accepts a list of sentences, even if we only have one...\n",
        "    vectorized_sentence = self.vectorizer.transform([joined_sentence])\n",
        "    \n",
        "    # classifying the vectorized sentence:\n",
        "    return self.classifier.predict(vectorized_sentence)\n",
        "\n",
        "evaluate_classifier(test_examples, NaiveBayesClassifier(train_examples))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.794431554524362"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}